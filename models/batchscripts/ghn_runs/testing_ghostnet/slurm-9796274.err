wandb: Currently logged in as: jakobs. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.12.21
wandb: Run data is saved locally in /home/serlierj/batchscripts/testing_ghostnet/wandb/run-20220726_210832-1ph0wiwx
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run helpful-eon-3
wandb: ‚≠êÔ∏è View project at https://wandb.ai/jakobs/uncategorized
wandb: üöÄ View run at https://wandb.ai/jakobs/uncategorized/runs/1ph0wiwx
/home/serlierj/envs/wild/lib/python3.7/site-packages/torchmetrics/utilities/prints.py:36: UserWarning: Metric `AUROC` will save all targets and predictions in buffer. For large datasets this may lead to large memory footprint.
  warnings.warn(*args, **kwargs)
Multiprocessing is handled by SLURM.
GPU available: True, used: True
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

  | Name          | Type             | Params
---------------------------------------------------
0 | model         | GhostNet         | 4.0 M 
1 | loss          | CrossEntropyLoss | 0     
2 | val_confusion | ConfusionMatrix  | 0     
3 | train_acc     | Accuracy         | 0     
4 | train_f1      | F1Score          | 0     
5 | train_auroc   | AUROC            | 0     
6 | val_acc       | Accuracy         | 0     
7 | val_f1        | F1Score          | 0     
8 | val_auroc     | AUROC            | 0     
---------------------------------------------------
4.0 M     Trainable params
0         Non-trainable params
4.0 M     Total params
16.186    Total estimated model params size (MB)
SLURM auto-requeueing enabled. Setting signal handlers.
/home/serlierj/envs/wild/lib/python3.7/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:245: PossibleUserWarning: The dataloader, val_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 12 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
  category=PossibleUserWarning,
/home/serlierj/envs/wild/lib/python3.7/site-packages/torch/functional.py:478: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at  ../aten/src/ATen/native/TensorShape.cpp:2895.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/home/serlierj/envs/wild/lib/python3.7/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:231: UserWarning: You called `self.log('confusion_matrix', ...)` in your `validation_epoch_end` but the value needs to be floating point. Converting it to torch.float32.
  f"You called `self.log({self.meta.name!r}, ...)` in your `{self.meta.fx}` but the value needs to"
/home/serlierj/envs/wild/lib/python3.7/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:245: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 12 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
  category=PossibleUserWarning,
slurmstepd: error: *** JOB 9796274 ON r31n1 CANCELLED AT 2022-07-27T03:08:40 DUE TO TIME LIMIT ***
