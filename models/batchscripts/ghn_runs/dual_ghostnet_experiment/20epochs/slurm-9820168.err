wandb: Currently logged in as: jakobs. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.12.21
wandb: Run data is saved locally in /home/serlierj/batchscripts/dual_ghostnet_experiment/20epochs/wandb/run-20220730_125255-349j41qc
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run bumbling-morning-30
wandb: â­ï¸ View project at https://wandb.ai/jakobs/uncategorized
wandb: ğŸš€ View run at https://wandb.ai/jakobs/uncategorized/runs/349j41qc
/home/serlierj/envs/wild/lib/python3.7/site-packages/torchmetrics/utilities/prints.py:36: UserWarning: Metric `AUROC` will save all targets and predictions in buffer. For large datasets this may lead to large memory footprint.
  warnings.warn(*args, **kwargs)
Multiprocessing is handled by SLURM.
GPU available: True, used: True
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

  | Name          | Type             | Params
---------------------------------------------------
0 | model         | DualGhostNet     | 7.8 M 
1 | loss          | CrossEntropyLoss | 0     
2 | val_confusion | ConfusionMatrix  | 0     
3 | train_acc     | Accuracy         | 0     
4 | train_f1      | F1Score          | 0     
5 | train_auroc   | AUROC            | 0     
6 | val_acc       | Accuracy         | 0     
7 | val_f1        | F1Score          | 0     
8 | val_auroc     | AUROC            | 0     
---------------------------------------------------
7.8 M     Trainable params
0         Non-trainable params
7.8 M     Total params
31.274    Total estimated model params size (MB)
SLURM auto-requeueing enabled. Setting signal handlers.
/home/serlierj/envs/wild/lib/python3.7/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:245: PossibleUserWarning: The dataloader, val_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 12 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
  category=PossibleUserWarning,
/home/serlierj/envs/wild/lib/python3.7/site-packages/torch/functional.py:478: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at  ../aten/src/ATen/native/TensorShape.cpp:2895.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
/home/serlierj/envs/wild/lib/python3.7/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:231: UserWarning: You called `self.log('confusion_matrix', ...)` in your `validation_epoch_end` but the value needs to be floating point. Converting it to torch.float32.
  f"You called `self.log({self.meta.name!r}, ...)` in your `{self.meta.fx}` but the value needs to"
/home/serlierj/envs/wild/lib/python3.7/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:245: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 12 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
  category=PossibleUserWarning,
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.294 MB of 0.294 MB uploaded (0.000 MB deduped)wandb: \ 0.294 MB of 0.308 MB uploaded (0.000 MB deduped)wandb: | 0.294 MB of 0.308 MB uploaded (0.000 MB deduped)wandb: / 0.308 MB of 0.308 MB uploaded (0.000 MB deduped)wandb: - 0.308 MB of 0.308 MB uploaded (0.000 MB deduped)wandb: \ 0.308 MB of 0.308 MB uploaded (0.000 MB deduped)wandb: | 0.308 MB of 0.308 MB uploaded (0.000 MB deduped)wandb: / 0.308 MB of 0.308 MB uploaded (0.000 MB deduped)wandb: - 0.308 MB of 0.308 MB uploaded (0.000 MB deduped)wandb: \ 0.308 MB of 0.308 MB uploaded (0.000 MB deduped)wandb: | 0.308 MB of 0.308 MB uploaded (0.000 MB deduped)wandb:                                                                                
wandb: 
wandb: Run history:
wandb:   class_0_precision â–â–â–ˆâ–â–‚â–ƒâ–‚â–â–„â–„
wandb:      class_0_recall â–ˆâ–ˆâ–â–‡â–‡â–†â–ˆâ–ˆâ–…â–…
wandb:   class_1_precision â–â–â–â–â–â–â–â–â–â–
wandb:   class_2_precision â–…â–â–‚â–…â–†â–†â–ˆâ–†â–‡â–…
wandb:      class_2_recall â–‚â–†â–â–„â–†â–ƒâ–â–ˆâ–…â–ˆ
wandb:   class_3_precision â–â–â–â–â–â–â–â–â–â–
wandb:   class_4_precision â–†â–ˆâ–â–‡â–†â–…â–„â–ˆâ–…â–†
wandb:      class_4_recall â–ƒâ–â–…â–„â–‡â–‡â–‡â–†â–ˆâ–‡
wandb:   class_5_precision â–â–â–â–â–â–â–â–â–â–
wandb:    confusion_matrix â–â–â–â–â–â–â–â–â–â–
wandb:               epoch â–â–‚â–ƒâ–ƒâ–„â–…â–†â–†â–‡â–ˆ
wandb: trainer/global_step â–â–â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–…â–…â–†â–†â–†â–†â–‡â–‡â–ˆ
wandb:             val_acc â–†â–†â–â–†â–‡â–†â–†â–ˆâ–‡â–‡
wandb:              val_f1 â–†â–†â–â–†â–‡â–†â–†â–ˆâ–‡â–‡
wandb:            val_loss â–‚â–‚â–ˆâ–‚â–‚â–ƒâ–‚â–â–‚â–„
wandb: 
wandb: Run summary:
wandb:   class_0_precision 0.82252
wandb:      class_0_recall 0.68699
wandb:   class_1_precision 0.0
wandb:      class_1_recall nan
wandb:   class_2_precision 0.39521
wandb:      class_2_recall 0.73217
wandb:   class_3_precision 0.0
wandb:      class_3_recall nan
wandb:   class_4_precision 0.70903
wandb:      class_4_recall 0.67212
wandb:   class_5_precision 0.0
wandb:      class_5_recall nan
wandb:    confusion_matrix 186.19444
wandb:               epoch 9
wandb: trainer/global_step 4459
wandb:             val_acc 0.68596
wandb:              val_f1 0.68596
wandb:            val_loss 1.07034
wandb: 
wandb: Synced bumbling-morning-30: https://wandb.ai/jakobs/uncategorized/runs/349j41qc
wandb: Synced 5 W&B file(s), 11 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20220730_125255-349j41qc/logs
